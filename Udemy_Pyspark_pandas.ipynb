{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a501657",
   "metadata": {},
   "source": [
    "First warning\n",
    "\n",
    "***import databricks.koalas as ks***\n",
    "\n",
    "Ya no tiene soporte a partir de pyspark 3.2 ya que pyspark ya la incluye en las versiones de \n",
    "3.3 como un modulo integrado de ***\"API de pandas en Spark\" portado desde Koalas.***\n",
    "Por lo que en su lugar se utiliza:\n",
    "\n",
    "***import pyspark.pandas as ps***\n",
    "\n",
    "Second Warning\n",
    "\n",
    "No se configuró la variable de entorno raíz: ***'PYARROW_IGNORE_TIMEZONE'***. Es necesario establecer esta variable de entorno en '1' tanto en el lado del controlador como en el del ejecutor si usa pyarrow>=2.0.0. Koalas lo configurará por usted, pero no funciona si ya se ha iniciado un Sparkcontext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "414735f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "import pyspark.pandas as ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ef020e",
   "metadata": {},
   "source": [
    "Se le asigna indices al Dataframe empezando desde 0 y podemos definir una columna del dataset para usarla como indice    \n",
    "(cualquier columna) para ello utilizamos index_col. De lo contario, si no se especifica, se puede adjuntar el indice predeterminado, lo cual puede causar\n",
    "una sobrecarga adicional. \n",
    "ESTO TAMBIÉN PUEDE APLICAR EN PANDAS\n",
    "Aqui no lo use porque después no me deja operar sobre esa columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba66fa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 78.1 ms\n",
      "Wall time: 23.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayra.cid\\Anaconda3\\envs\\Udemy_osos\\lib\\site-packages\\pyspark\\pandas\\utils.py:975: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `read_csv`, the default index is attached which can cause additional overhead.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                    float64\n",
       "title                  object\n",
       "is_paid                object\n",
       "price                  object\n",
       "headline               object\n",
       "num_subscribers        object\n",
       "avg_rating             object\n",
       "num_reviews            object\n",
       "num_comments           object\n",
       "num_lectures           object\n",
       "content_length_min    float64\n",
       "published_time         object\n",
       "last_update_date       object\n",
       "category               object\n",
       "subcategory            object\n",
       "topic                  object\n",
       "language               object\n",
       "course_url             object\n",
       "instructor_name        object\n",
       "instructor_url         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Todos menos content_length_min y id Float) son objetc\n",
    "Udemy_DF = ps.read_csv('C:/Users/mayra.cid/Documents/Repositorios/Udemy_Dataset/Course_info.csv')\n",
    "Udemy_DF.dtypes\n",
    "#Udemy_DF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae8fbbc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert fractions with missing values to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:8\u001b[0m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Udemy_osos\\lib\\site-packages\\pyspark\\pandas\\frame.py:8625\u001b[0m, in \u001b[0;36mDataFrame.astype\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   8623\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col_name, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   8624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m col_name \u001b[38;5;129;01min\u001b[39;00m dtype_dict:\n\u001b[1;32m-> 8625\u001b[0m         applied\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   8626\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   8627\u001b[0m         applied\u001b[38;5;241m.\u001b[39mappend(col)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Udemy_osos\\lib\\site-packages\\pyspark\\pandas\\base.py:827\u001b[0m, in \u001b[0;36mIndexOpsMixin.astype\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m: IndexOpsLike, dtype: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m, Dtype]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m IndexOpsLike:\n\u001b[0;32m    794\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;124;03m    Cast a pandas-on-Spark object to a specified dtype ``dtype``.\u001b[39;00m\n\u001b[0;32m    796\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;124;03m    Int64Index([1, 2], dtype='int64', name='a')\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Udemy_osos\\lib\\site-packages\\pyspark\\pandas\\data_type_ops\\num_ops.py:397\u001b[0m, in \u001b[0;36mFractionalOps.astype\u001b[1;34m(self, index_ops, dtype)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, extension_dtypes):\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute.eager_check\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m index_ops\u001b[38;5;241m.\u001b[39mhasnans:\n\u001b[1;32m--> 397\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m with missing values to integer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretty_name\n\u001b[0;32m    399\u001b[0m         )\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, CategoricalDtype):\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _as_categorical_type(index_ops, dtype, spark_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert fractions with missing values to integer"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Cambio del tipo de dato\n",
    "#Udemy_DF.astype({'id': int})\n",
    "Udemy_DF['id'] = Udemy_DF['id'].astype('int64') \n",
    "Udemy_DF['num_subscribers'] = Udemy_DF['num_subscribers'].astype('int64')\n",
    "Udemy_DF['num_reviews'] = Udemy_DF['num_reviews'].astype('int64')\n",
    "Udemy_DF['num_comments'] = Udemy_DF['num_comments'].astype('int64')\n",
    "Udemy_DF['num_lectures'] = Udemy_DF['num_lectures'].astype('int64')\n",
    "Udemy_DF.astype({'content_length_min': int})\n",
    "\n",
    "\n",
    "\n",
    "Udemy_DF.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f0536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
